{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesado: 01_mean_temperature-reanalysis-monthly-layer-eea_trans_mediterranean-latitude-1940-2023-v1.0.csv -> Temp media\n",
      "Procesado: 03_heating_degree_days-reanalysis-monthly-layer-eea_trans_mediterranean-latitude-1940-2023-v1.0.csv -> Dias calefaccion\n",
      "Procesado: 04_cooling_degree_days-reanalysis-monthly-layer-eea_trans_mediterranean-latitude-1940-2023-v1.0.csv -> Dias refrigeracion\n",
      "Procesado: 11_frost_days-reanalysis-monthly-layer-eea_trans_mediterranean-latitude-1940-2023-v1.0.csv -> Dias helada\n",
      "Procesado: l1_daily_maximum_temperature-reanalysis-monthly-max-layer-eea_trans_mediterranean-latitude-1940-2023-v1.0.csv -> Max temp monthly max\n",
      "Procesado: l1_daily_maximum_temperature-reanalysis-monthly-mean-layer-eea_trans_mediterranean-latitude-1940-2023-v1.0.csv -> Max temp monthly mean\n",
      "Procesado: l1_daily_maximum_temperature-reanalysis-monthly-min-layer-eea_trans_mediterranean-latitude-1940-2023-v1.0.csv -> Max temp monthly min\n",
      "Procesado: l2_daily_minimum_temperature-reanalysis-monthly-max-layer-eea_trans_mediterranean-latitude-1940-2023-v1.0.csv -> Min temp monthly max\n",
      "Procesado: l2_daily_minimum_temperature-reanalysis-monthly-mean-layer-eea_trans_mediterranean-latitude-1940-2023-v1.0.csv -> Min temp monthly mean\n",
      "Procesado: l2_daily_minimum_temperature-reanalysis-monthly-min-layer-eea_trans_mediterranean-latitude-1940-2023-v1.0.csv -> Min temp monthly min\n",
      "Archivo final generado: datos_climaticos_unidos_limpio.csv\n",
      "Columnas en el archivo final: time, Temp media, Dias calefaccion, Dias refrigeracion, Dias helada, Max temp monthly max, Max temp monthly mean, Max temp monthly min, Min temp monthly max, Min temp monthly mean, Min temp monthly min\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Ruta a la carpeta donde están tus archivos CSV\n",
    "carpeta = \"ClimateDataStore\"\n",
    "\n",
    "# Diccionario de mapeo para renombrar archivos\n",
    "mapeo_archivos = {\n",
    "     \"01_mean_temperature\": \"Temp media\",\n",
    "    \"03_heating_degree_days\": \"Dias calefaccion\",\n",
    "    \"04_cooling_degree_days\": \"Dias refrigeracion\",\n",
    "    \"11_frost_days\": \"Dias helada\",\n",
    "    \"l1_daily_maximum_temperature-reanalysis-monthly-max-layer-\": \"Max temp monthly max\",\n",
    "    \"l1_daily_maximum_temperature-reanalysis-monthly-mean-layer\": \"Max temp monthly mean\",\n",
    "    \"l1_daily_maximum_temperature-reanalysis-monthly-min-layer\": \"Max temp monthly min\",\n",
    "    \"l2_daily_minimum_temperature-reanalysis-monthly-max-layer\": \"Min temp monthly max\",\n",
    "    \"l2_daily_minimum_temperature-reanalysis-monthly-mean-layer\": \"Min temp monthly mean\",\n",
    "    \"l2_daily_minimum_temperature-reanalysis-monthly-min-layer\": \"Min temp monthly min\"\n",
    "}\n",
    "\n",
    "# Lista para almacenar DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Paso 1: Copiar y procesar los archivos originales\n",
    "for archivo in os.listdir(carpeta):\n",
    "    # Ignorar archivos que no son CSV o que sean el resultado final\n",
    "    if not archivo.endswith(\".csv\") or archivo == \"datos_climaticos_unidos.csv\":\n",
    "        continue\n",
    "        \n",
    "    ruta_completa = os.path.join(carpeta, archivo)\n",
    "    \n",
    "    # Determinar el nuevo nombre para la columna\n",
    "    nombre_columna = None\n",
    "    for clave, valor in mapeo_archivos.items():\n",
    "        if clave in archivo:\n",
    "            nombre_columna = valor\n",
    "            break\n",
    "    \n",
    "    if nombre_columna is None:\n",
    "        print(f\"Ignorando archivo sin coincidencia: {archivo}\")\n",
    "        continue\n",
    "    \n",
    "    # Leer el archivo CSV\n",
    "    try:\n",
    "        df = pd.read_csv(ruta_completa)\n",
    "        \n",
    "        # Filtrar columnas\n",
    "        cols_a_mantener = ['time']\n",
    "        for col in df.columns:\n",
    "            if col not in ['time', 'transnational_regions', 'realization']:\n",
    "                cols_a_mantener.append(col)\n",
    "        \n",
    "        df_reduced = df[cols_a_mantener].copy()\n",
    "        \n",
    "        # Renombrar las columnas de valor (excepto time)\n",
    "        for col in df_reduced.columns:\n",
    "            if col != 'time':\n",
    "                df_reduced = df_reduced.rename(columns={col: nombre_columna})\n",
    "        \n",
    "        # Convertir time a datetime si es posible\n",
    "        try:\n",
    "            df_reduced['time'] = pd.to_datetime(df_reduced['time'])\n",
    "        except:\n",
    "            pass  # Si no se puede convertir, dejarlo como está\n",
    "        \n",
    "        # Guardar DataFrame\n",
    "        dfs.append(df_reduced)\n",
    "        print(f\"Procesado: {archivo} -> {nombre_columna}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar {archivo}: {e}\")\n",
    "\n",
    "# Paso 2: Unir todos los DataFrames\n",
    "if dfs:\n",
    "    # Establecer 'time' como índice para todos los DataFrames\n",
    "    for i in range(len(dfs)):\n",
    "        dfs[i] = dfs[i].set_index('time')\n",
    "    \n",
    "    # Unir todos los DataFrames en uno solo\n",
    "    df_final = pd.concat(dfs, axis=1)\n",
    "    \n",
    "    # Si hay columnas con el mismo nombre, agregar sufijo\n",
    "    df_final = df_final.loc[:,~df_final.columns.duplicated()]\n",
    "    \n",
    "    # Restablecer el índice para que 'time' vuelva a ser una columna\n",
    "    df_final = df_final.reset_index()\n",
    "    \n",
    "    # Ordenar el DataFrame final por la columna time\n",
    "    df_final = df_final.sort_values('time')\n",
    "    \n",
    "    # Guardar el DataFrame final como CSV\n",
    "    ruta_final = os.path.join(carpeta, \"datos_climaticos_unidos_limpio.csv\")\n",
    "    df_final.to_csv(ruta_final, index=False)\n",
    "    \n",
    "    print(f\"Archivo final generado: datos_climaticos_unidos_limpio.csv\")\n",
    "    print(f\"Columnas en el archivo final: {', '.join(df_final.columns)}\")\n",
    "else:\n",
    "    print(\"No se encontraron archivos CSV para procesar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>Temp media</th>\n",
       "      <th>Dias calefaccion</th>\n",
       "      <th>Dias efrigeracion</th>\n",
       "      <th>Dias helada</th>\n",
       "      <th>Max temp monthly max</th>\n",
       "      <th>Max temp monthly mean</th>\n",
       "      <th>Max temp monthly min</th>\n",
       "      <th>Min temp monthly max</th>\n",
       "      <th>Min temp monthly mean</th>\n",
       "      <th>Min temp monthly min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1940-01-01</td>\n",
       "      <td>274.075920</td>\n",
       "      <td>451.715785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.126696</td>\n",
       "      <td>283.069720</td>\n",
       "      <td>277.383849</td>\n",
       "      <td>269.902017</td>\n",
       "      <td>278.237537</td>\n",
       "      <td>271.128065</td>\n",
       "      <td>262.126020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1940-02-01</td>\n",
       "      <td>277.556366</td>\n",
       "      <td>321.482865</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>11.215833</td>\n",
       "      <td>287.332116</td>\n",
       "      <td>281.234155</td>\n",
       "      <td>272.256102</td>\n",
       "      <td>279.754464</td>\n",
       "      <td>274.282298</td>\n",
       "      <td>265.125066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1940-03-01</td>\n",
       "      <td>280.152728</td>\n",
       "      <td>266.586311</td>\n",
       "      <td>0.185722</td>\n",
       "      <td>8.919249</td>\n",
       "      <td>292.312914</td>\n",
       "      <td>284.259968</td>\n",
       "      <td>276.465635</td>\n",
       "      <td>283.515866</td>\n",
       "      <td>276.474440</td>\n",
       "      <td>269.207108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1940-04-01</td>\n",
       "      <td>283.823841</td>\n",
       "      <td>156.481179</td>\n",
       "      <td>0.591104</td>\n",
       "      <td>2.986531</td>\n",
       "      <td>294.499065</td>\n",
       "      <td>287.964766</td>\n",
       "      <td>281.143995</td>\n",
       "      <td>285.060999</td>\n",
       "      <td>279.994870</td>\n",
       "      <td>274.153194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1940-05-01</td>\n",
       "      <td>288.069310</td>\n",
       "      <td>69.057994</td>\n",
       "      <td>5.698343</td>\n",
       "      <td>0.450916</td>\n",
       "      <td>298.847128</td>\n",
       "      <td>292.079620</td>\n",
       "      <td>285.651978</td>\n",
       "      <td>288.953641</td>\n",
       "      <td>284.150881</td>\n",
       "      <td>280.160487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time  Temp media  Dias calefaccion  Dias efrigeracion  Dias helada  \\\n",
       "0 1940-01-01  274.075920        451.715785           0.000000    17.126696   \n",
       "1 1940-02-01  277.556366        321.482865           0.001133    11.215833   \n",
       "2 1940-03-01  280.152728        266.586311           0.185722     8.919249   \n",
       "3 1940-04-01  283.823841        156.481179           0.591104     2.986531   \n",
       "4 1940-05-01  288.069310         69.057994           5.698343     0.450916   \n",
       "\n",
       "   Max temp monthly max  Max temp monthly mean  Max temp monthly min  \\\n",
       "0            283.069720             277.383849            269.902017   \n",
       "1            287.332116             281.234155            272.256102   \n",
       "2            292.312914             284.259968            276.465635   \n",
       "3            294.499065             287.964766            281.143995   \n",
       "4            298.847128             292.079620            285.651978   \n",
       "\n",
       "   Min temp monthly max  Min temp monthly mean  Min temp monthly min  \n",
       "0            278.237537             271.128065            262.126020  \n",
       "1            279.754464             274.282298            265.125066  \n",
       "2            283.515866             276.474440            269.207108  \n",
       "3            285.060999             279.994870            274.153194  \n",
       "4            288.953641             284.150881            280.160487  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1008 entries, 0 to 1007\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   time                   1008 non-null   datetime64[ns]\n",
      " 1   Temp media             1008 non-null   float64       \n",
      " 2   Dias calefaccion       1008 non-null   float64       \n",
      " 3   Dias efrigeracion      1008 non-null   float64       \n",
      " 4   Dias helada            1008 non-null   float64       \n",
      " 5   Max temp monthly max   1008 non-null   float64       \n",
      " 6   Max temp monthly mean  1008 non-null   float64       \n",
      " 7   Max temp monthly min   1008 non-null   float64       \n",
      " 8   Min temp monthly max   1008 non-null   float64       \n",
      " 9   Min temp monthly mean  1008 non-null   float64       \n",
      " 10  Min temp monthly min   1008 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(10)\n",
      "memory usage: 86.8 KB\n"
     ]
    }
   ],
   "source": [
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exportamos el archivo\n",
    "df_final.to_csv('datos_climaticos_unidos_limpio.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "last",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
